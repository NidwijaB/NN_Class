{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Q No.2.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyPm9nGV8Na3rcxRQVAGwceD"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yFi0FxT5sgQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1642434674786,
     "user_tz": -345,
     "elapsed": 454,
     "user": {
      "displayName": "Rishav Acharya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJjmlIcdjuYHBYopjvFbZ7ZjhKusDuWowVd0v6=s64",
      "userId": "10687703206590260356"
     }
    },
    "outputId": "d830210e-595c-4b58-e5f3-c698ca5143e4",
    "ExecuteTime": {
     "end_time": "2025-03-08T18:18:05.443932Z",
     "start_time": "2025-03-08T18:18:05.222742Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "2.\tWrite a python program to train AND Gate Using Perceptron Learning Algorithm.\n",
    "\"\"\"\n",
    "class AndPreceptron:\n",
    "    def __init__(self, train_size, train_data, target_data, learning_rate):\n",
    "        self.input_length=train_size\n",
    "        self.training_data=train_data\n",
    "        self.target_data=target_data\n",
    "        self.learning_rate=learning_rate\n",
    "        self.weights=np.random.randn(self.input_length) #initializing random weights\n",
    "        self.bias=np.random.uniform() #initializaing bias randomly\n",
    "\n",
    "    def summing_node(self, input_data):\n",
    "        return np.dot(self.weights,input_data)+self.bias\n",
    "\n",
    "    def activation_fn(self, sum_result):\n",
    "        return 1 if sum_result >0 else 0\n",
    "\n",
    "    def update_weight_and_bias(self,training,target,output):\n",
    "        error=target-output\n",
    "        self.weights+=self.learning_rate * error * np.array(training)\n",
    "        self.bias+=self.learning_rate * error\n",
    "\n",
    "    def train(self,epochs=20):\n",
    "        print(f\"Initial Weights: {self.weights}, Bias: {self.bias}\")\n",
    "        print('Training is now begun')\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch + 1} started...\")\n",
    "            errors=0\n",
    "            for i in range(len(self.training_data)):\n",
    "                sum_result=self.summing_node(self.training_data[i])\n",
    "                output=self.activation_fn(sum_result)\n",
    "                if output!=self.target_data[i]:\n",
    "                    self.update_weight_and_bias(self.training_data[i], self.target_data[i], output)\n",
    "                    errors=errors+1\n",
    "            print(f\"Weights: {self.weights}, Bias: {self.bias}\")\n",
    "            print(f\"Epoch {epoch + 1} completed. Misclassifications: {errors}\\n\")\n",
    "\n",
    "            if errors == 0:  # Stop training if all classifications are correct\n",
    "                print(\"Training completed successfully.\")\n",
    "                break\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        summed_result = np.dot(self.weights, np.array(input_data)) + self.bias\n",
    "        output = self.activation_fn(summed_result)\n",
    "        print(f\"Input: {input_data} => Output: {output}\")\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data = [[0,0],[0,1],[1,0],[1,1]]\n",
    "target = [0,0,0,1]\n",
    "p = AndPreceptron(2,train_data,target,learning_rate=0.1)\n",
    "p.train()\n",
    "p.predict([1,0])\n",
    "p.predict([0,1])\n",
    "p.predict([1,1])\n",
    "p.predict([0,0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights: [1.14617507 1.58194855], Bias: 0.5704368381916501\n",
      "Training is now begun\n",
      "Epoch 1 started...\n",
      "Weights: [1.04617507 1.48194855], Bias: 0.2704368381916502\n",
      "Epoch 1 completed. Misclassifications: 3\n",
      "\n",
      "Epoch 2 started...\n",
      "Weights: [0.94617507 1.38194855], Bias: -0.029563161808349808\n",
      "Epoch 2 completed. Misclassifications: 3\n",
      "\n",
      "Epoch 3 started...\n",
      "Weights: [0.84617507 1.28194855], Bias: -0.22956316180834982\n",
      "Epoch 3 completed. Misclassifications: 2\n",
      "\n",
      "Epoch 4 started...\n",
      "Weights: [0.74617507 1.18194855], Bias: -0.42956316180834986\n",
      "Epoch 4 completed. Misclassifications: 2\n",
      "\n",
      "Epoch 5 started...\n",
      "Weights: [0.64617507 1.08194855], Bias: -0.6295631618083498\n",
      "Epoch 5 completed. Misclassifications: 2\n",
      "\n",
      "Epoch 6 started...\n",
      "Weights: [0.64617507 0.98194855], Bias: -0.7295631618083498\n",
      "Epoch 6 completed. Misclassifications: 1\n",
      "\n",
      "Epoch 7 started...\n",
      "Weights: [0.64617507 0.88194855], Bias: -0.8295631618083498\n",
      "Epoch 7 completed. Misclassifications: 1\n",
      "\n",
      "Epoch 8 started...\n",
      "Weights: [0.64617507 0.78194855], Bias: -0.9295631618083497\n",
      "Epoch 8 completed. Misclassifications: 1\n",
      "\n",
      "Epoch 9 started...\n",
      "Weights: [0.64617507 0.78194855], Bias: -0.9295631618083497\n",
      "Epoch 9 completed. Misclassifications: 0\n",
      "\n",
      "Training completed successfully.\n",
      "Input: [1, 0] => Output: 0\n",
      "Input: [0, 1] => Output: 0\n",
      "Input: [1, 1] => Output: 1\n",
      "Input: [0, 0] => Output: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  }
 ]
}
